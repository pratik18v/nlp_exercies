{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional exercise #1  (CSE 628) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doubts:\n",
    "1. Can a N-gram contain words from two different sentences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "from nltk import bigrams, trigrams\n",
    "import string\n",
    "from decimal import *\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "#Setting decimal point precision\n",
    "getcontext().prec = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 1000 sentences\n",
      "Size of test set: 1000 sentences\n"
     ]
    }
   ],
   "source": [
    "#Importing data\n",
    "new_data = []\n",
    "data = gutenberg.sents('austen-sense.txt')\n",
    "data = data[2:]\n",
    "\n",
    "#Add sentence de-limiters, remove punctuations and switch to lower-case\n",
    "for d in data:\n",
    "    d = [''.join(c for c in s if c not in string.punctuation) for s in d]\n",
    "    d = [s for s in d if s]\n",
    "    d.insert(0,'<s>')\n",
    "    d.append('</s>')\n",
    "    d = [str(w.lower()) for w in d]\n",
    "    new_data.append(d)\n",
    "    \n",
    "#The first 1000 sentences go into training set\n",
    "train_set = new_data[0:1000]\n",
    "#The second 1000 sentences go into test set\n",
    "test_set = new_data[1000:2000]\n",
    "\n",
    "print \"Size of training set: {} sentences\".format(len(train_set))\n",
    "print \"Size of test set: {} sentences\".format(len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unigrams: 2882\n",
      "Number of bigrams: 14341\n",
      "Number of trigrams: 21306\n"
     ]
    }
   ],
   "source": [
    "train_words = [val for sublist in train_set for val in sublist]\n",
    "num_words = len(train_words)\n",
    "\n",
    "#Calculating bigrams\n",
    "train_bigrams = list(bigrams(train_words))\n",
    "#Calculating trigrams\n",
    "train_trigrams = list(trigrams(train_words))\n",
    "\n",
    "#Counting unigrams, bigrams and trigrams encountered in the training set\n",
    "uni_count = dict([(item, train_words.count(item)) for item in sorted(set(train_words))])\n",
    "bi_count = dict([(item, train_bigrams.count(item)) for item in sorted(set(train_bigrams))])\n",
    "tri_count = dict([(item, train_trigrams.count(item)) for item in sorted(set(train_trigrams))])\n",
    "\n",
    "print \"Number of unigrams: {}\".format(len(uni_count))\n",
    "print \"Number of bigrams: {}\".format(len(bi_count))\n",
    "print \"Number of trigrams: {}\".format(len(tri_count))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can observe that the number of unqiue N-grams increases on increasing the value of N. This is because, eg - repeating 3-word combinations (or trigrams) are rarer than repeating 2-word combinations (or bigrams), which in turn are rarer than repeating single words (or unigrams)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of test sentences that get a non-zero probability according to unigram model: 388 (out of 1000)\n"
     ]
    }
   ],
   "source": [
    "#Calculating MLE on test sentences using unigram model\n",
    "test_uni_mle = []\n",
    "for i in range(len(test_set)):\n",
    "    uni_mle = 1\n",
    "    for t in test_set[i][1:]:\n",
    "        if t in uni_count.keys():\n",
    "            uni_mle *= Decimal(uni_count[t])/Decimal(num_words)\n",
    "        else:\n",
    "            uni_mle = 0\n",
    "            break\n",
    "    test_uni_mle.append(uni_mle)\n",
    "\n",
    "print \"# of test sentences that get a non-zero probability according to unigram model: {} (out of {})\".format(\n",
    "    np.count_nonzero(test_uni_mle), len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of test sentences that get a non-zero probability according to bigram model: 29 (out of 1000)\n"
     ]
    }
   ],
   "source": [
    "#Calculating MLE on test sentences using bigram model\n",
    "test_bi_mle = []\n",
    "for i in range(len(test_set)):\n",
    "    bi_mle = 1\n",
    "    test_bigrams = list(bigrams(test_set[i]))\n",
    "    for j in range(len(test_bigrams)):\n",
    "        if test_bigrams[j] in bi_count.keys():\n",
    "            bi_mle *= Decimal(bi_count[test_bigrams[j]])/Decimal(uni_count[test_bigrams[j][0]])\n",
    "        else:\n",
    "            bi_mle = 0\n",
    "            break\n",
    "    test_bi_mle.append(bi_mle)\n",
    "\n",
    "print \"# of test sentences that get a non-zero probability according to bigram model: {} (out of {})\".format(\n",
    "    np.count_nonzero(test_bi_mle), len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of test sentences that get a non-zero probability according to trigram model: 16 (out of 1000)\n"
     ]
    }
   ],
   "source": [
    "#Calculating MLE on test sentences using trigram model\n",
    "test_tri_mle = []\n",
    "for i in range(len(test_set)):\n",
    "    tri_mle = 1\n",
    "    test_trigrams = list(trigrams(test_set[i]))\n",
    "    #if sentence only has less than 3 words, meaning no trigrams\n",
    "    if len(test_trigrams) == 0:\n",
    "        tri_mle = 0\n",
    "        continue\n",
    "    for j in range(len(test_trigrams)):\n",
    "        if test_trigrams[j] in tri_count.keys():\n",
    "            tri_mle *= Decimal(tri_count[test_trigrams[j]])/Decimal(bi_count[(test_trigrams[j][0],\n",
    "                                                                              test_trigrams[j][1])])\n",
    "        else:\n",
    "            tri_mle = 0\n",
    "            break\n",
    "    test_tri_mle.append(tri_mle)\n",
    "\n",
    "print \"# of test sentences that get a non-zero probability according to trigram model: {} (out of {})\".format(\n",
    "    np.count_nonzero(test_tri_mle), len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated random sentences:\n",
      "<s> for time never each atone </s>\n",
      "<s> which future on them assurance of a general </s>\n",
      "<s> exhausted tendency either long death think relative to </s>\n",
      "<s> pencil be elinor of sure always john benefit would </s>\n",
      "<s> he the as we address persuading </s>\n"
     ]
    }
   ],
   "source": [
    "#Making up 5 non-sensical sentences from training set and calculating their MLE estimates\n",
    "all_rands = []\n",
    "sample_words = filter(lambda c: c != '<s>' and c != '</s>', train_words)\n",
    "print \"Generated random sentences:\"\n",
    "for i in range(5):\n",
    "    #Select sentence length at random\n",
    "    sent_len = random.sample(range(5,10),1)\n",
    "    idxs = random.sample(range(len(sample_words)), sent_len[0])\n",
    "    rand_sent = [sample_words[i] for i in idxs]\n",
    "    rand_sent.insert(0,'<s>')\n",
    "    rand_sent.append('</s>')\n",
    "    all_rands.append(rand_sent)\n",
    "    print ' '.join(rand_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram MLEs for the random sentences: \n",
      "1. 1.60733E-17\n",
      "2. 6.82827E-23\n",
      "3. 5.22307E-30\n",
      "4. 6.96985E-28\n",
      "5. 1.87249E-18\n",
      "\n",
      "Bigram MLEs for the random sentences: \n",
      "1. 0\n",
      "2. 0\n",
      "3. 0\n",
      "4. 0\n",
      "5. 0\n",
      "\n",
      "Trigram MLEs for the random sentences: \n",
      "1. 0\n",
      "2. 0\n",
      "3. 0\n",
      "4. 0\n",
      "5. 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rand_uni_mle = []\n",
    "for i in range(len(all_rands)):\n",
    "    uni_mle = 1\n",
    "    for t in all_rands[i][1:]:\n",
    "        if t in uni_count.keys():\n",
    "            uni_mle *= Decimal(uni_count[t])/Decimal(num_words)\n",
    "        else:\n",
    "            uni_mle = 0\n",
    "            break\n",
    "    rand_uni_mle.append(uni_mle)\n",
    "print \"Unigram MLEs for the random sentences: \\n1. {}\\n2. {}\\n3. {}\\n4. {}\\n5. {}\\n\".format(rand_uni_mle[0], \n",
    "                                                rand_uni_mle[1], rand_uni_mle[2], rand_uni_mle[3], rand_uni_mle[4])\n",
    "\n",
    "rand_bi_mle = []\n",
    "for i in range(len(all_rands)):\n",
    "    bi_mle = 1\n",
    "    rand_bigrams = list(bigrams(all_rands[i]))\n",
    "    for j in range(len(rand_bigrams)):\n",
    "        if rand_bigrams[j] in bi_count.keys():\n",
    "            bi_mle *= Decimal(bi_count[rand_bigrams[j]])/Decimal(uni_count[rand_bigrams[j][0]])\n",
    "        else:\n",
    "            bi_mle = 0\n",
    "            break\n",
    "    rand_bi_mle.append(bi_mle)\n",
    "\n",
    "print \"Bigram MLEs for the random sentences: \\n1. {}\\n2. {}\\n3. {}\\n4. {}\\n5. {}\\n\".format(rand_bi_mle[0], \n",
    "                                                rand_bi_mle[1], rand_bi_mle[2], rand_bi_mle[3], rand_bi_mle[4])\n",
    "\n",
    "rand_tri_mle = []\n",
    "for i in range(len(all_rands)):\n",
    "    tri_mle = 1\n",
    "    rand_trigrams = list(trigrams(all_rands[i]))\n",
    "    #if sentence only has less than 3 words, meaning no trigrams\n",
    "    if len(rand_trigrams) == 0:\n",
    "        tri_mle = 0\n",
    "        continue\n",
    "    for j in range(len(rand_trigrams)):\n",
    "        if rand_trigrams[j] in tri_count.keys():\n",
    "            tri_mle *= Decimal(tri_count[rand_trigrams[j]])/Decimal(bi_count[(rand_trigrams[j][0],\n",
    "                                                                              rand_trigrams[j][1])])\n",
    "        else:\n",
    "            tri_mle = 0\n",
    "            break\n",
    "    rand_tri_mle.append(tri_mle)\n",
    "\n",
    "print \"Trigram MLEs for the random sentences: \\n1. {}\\n2. {}\\n3. {}\\n4. {}\\n5. {}\\n\".format(rand_tri_mle[0], \n",
    "                                            rand_tri_mle[1], rand_tri_mle[2], rand_tri_mle[3], rand_tri_mle[4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(I)\n",
    "#Implementing add-1 smoothing with unigram model. V = #train plus test words\n",
    "add1_uni_mle = []\n",
    "for i in range(len(test_set)):\n",
    "    uni_mle = 1\n",
    "    for t in test_set[i][1:]:\n",
    "        if t in uni_count.keys():\n",
    "            uni_cnt = uni_count[t] + 1\n",
    "        else:\n",
    "            uni_mle = 1\n",
    "        uni_mle *= Decimal(uni_cnt)/(Decimal(num_words)+V)\n",
    "        \n",
    "    test_uni_mle.append(uni_mle)\n",
    "\n",
    "print \"# of test sentences that get a non-zero probability according to unigram model with add-1 smoothing: {} (out of {})\".format\n",
    "    (np.count_nonzero(test_uni_mle), len(test_set))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
